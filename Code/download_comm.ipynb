{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of Youtube video for which to download the comments Y-XHMlaJL-s\n",
      "Output filename (output format is line delimited JSON) football_video.json\n",
      "Limit the number of comments 50\n",
      "Downloading Youtube comments for video: Y-XHMlaJL-s\n",
      "Downloaded 50 comment(s)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import argparse\n",
    "import lxml.html\n",
    "import io\n",
    "\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "YOUTUBE_COMMENTS_URL = 'https://www.youtube.com/all_comments?v={youtube_id}'\n",
    "YOUTUBE_COMMENTS_AJAX_URL = 'https://www.youtube.com/comment_ajax'\n",
    "\n",
    "USER_AGENT = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36'\n",
    "\n",
    "\n",
    "def find_value(html, key, num_chars=2):\n",
    "    pos_begin = html.find(key) + len(key) + num_chars\n",
    "    pos_end = html.find('\"', pos_begin)\n",
    "    return html[pos_begin: pos_end]\n",
    "\n",
    "\n",
    "def extract_comments(html):\n",
    "    tree = lxml.html.fromstring(html)\n",
    "    item_sel = CSSSelector('.comment-item')\n",
    "    text_sel = CSSSelector('.comment-text-content')\n",
    "    time_sel = CSSSelector('.time')\n",
    "    author_sel = CSSSelector('.user-name')\n",
    "\n",
    "    for item in item_sel(tree):\n",
    "        yield {'cid': item.get('data-cid'),\n",
    "               'text': text_sel(item)[0].text_content(),\n",
    "               'time': time_sel(item)[0].text_content().strip(),\n",
    "               'author': author_sel(item)[0].text_content()}\n",
    "\n",
    "\n",
    "def extract_reply_cids(html):\n",
    "    tree = lxml.html.fromstring(html)\n",
    "    sel = CSSSelector('.comment-replies-header > .load-comments')\n",
    "    return [i.get('data-cid') for i in sel(tree)]\n",
    "\n",
    "\n",
    "def ajax_request(session, url, params, data, retries=10, sleep=20):\n",
    "    for _ in range(retries):\n",
    "        response = session.post(url, params=params, data=data)\n",
    "        if response.status_code == 200:\n",
    "            response_dict = json.loads(response.text)\n",
    "            return response_dict.get('page_token', None), response_dict['html_content']\n",
    "        else:\n",
    "            time.sleep(sleep)\n",
    "\n",
    "\n",
    "def download_comments(youtube_id, sleep=1):\n",
    "    session = requests.Session()\n",
    "    session.headers['User-Agent'] = USER_AGENT\n",
    "\n",
    "    # Get Youtube page with initial comments\n",
    "    response = session.get(YOUTUBE_COMMENTS_URL.format(youtube_id=youtube_id))\n",
    "    html = response.text\n",
    "    reply_cids = extract_reply_cids(html)\n",
    "\n",
    "    ret_cids = []\n",
    "    for comment in extract_comments(html):\n",
    "        ret_cids.append(comment['cid'])\n",
    "        yield comment\n",
    "\n",
    "    page_token = find_value(html, 'data-token')\n",
    "    session_token = find_value(html, 'XSRF_TOKEN', 4)\n",
    "\n",
    "    first_iteration = True\n",
    "\n",
    "    # Get remaining comments (the same as pressing the 'Show more' button)\n",
    "    while page_token:\n",
    "        data = {'video_id': youtube_id,\n",
    "                'session_token': session_token}\n",
    "\n",
    "        params = {'action_load_comments': 1,\n",
    "                  'order_by_time': True,\n",
    "                  'filter': youtube_id}\n",
    "\n",
    "        if first_iteration:\n",
    "            params['order_menu'] = True\n",
    "        else:\n",
    "            data['page_token'] = page_token\n",
    "\n",
    "        response = ajax_request(session, YOUTUBE_COMMENTS_AJAX_URL, params, data)\n",
    "        if not response:\n",
    "            break\n",
    "\n",
    "        page_token, html = response\n",
    "\n",
    "        reply_cids += extract_reply_cids(html)\n",
    "        for comment in extract_comments(html):\n",
    "            if comment['cid'] not in ret_cids:\n",
    "                ret_cids.append(comment['cid'])\n",
    "                yield comment\n",
    "\n",
    "        first_iteration = False\n",
    "        time.sleep(sleep)\n",
    "\n",
    "    # Get replies (the same as pressing the 'View all X replies' link)\n",
    "    for cid in reply_cids:\n",
    "        data = {'comment_id': cid,\n",
    "                'video_id': youtube_id,\n",
    "                'can_reply': 1,\n",
    "                'session_token': session_token}\n",
    "\n",
    "        params = {'action_load_replies': 1,\n",
    "                  'order_by_time': True,\n",
    "                  'filter': youtube_id,\n",
    "                  'tab': 'inbox'}\n",
    "\n",
    "        response = ajax_request(session, YOUTUBE_COMMENTS_AJAX_URL, params, data)\n",
    "        if not response:\n",
    "            break\n",
    "\n",
    "        _, html = response\n",
    "\n",
    "        for comment in extract_comments(html):\n",
    "            if comment['cid'] not in ret_cids:\n",
    "                ret_cids.append(comment['cid'])\n",
    "                yield comment\n",
    "        time.sleep(sleep)\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    '''\n",
    "        parser = argparse.ArgumentParser(add_help=False, description=('Download Youtube comments without using the Youtube API'))\n",
    "        parser.add_argument('--help', '-h', action='help', default=argparse.SUPPRESS, help='Show this help message and exit')\n",
    "        parser.add_argument('--youtubeid', '-y', help='ID of Youtube video for which to download the comments')\n",
    "        parser.add_argument('--output', '-o', help='Output filename (output format is line delimited JSON)')\n",
    "        parser.add_argument('--limit', '-l', type=int, help='Limit the number of comments')\n",
    "\n",
    "        try:\n",
    "            args = parser.parse_args(argv)\n",
    "\n",
    "            youtube_id = args.youtubeid\n",
    "            output = args.output\n",
    "            limit = args.limit\n",
    "\n",
    "            if not youtube_id or not output:\n",
    "                parser.print_usage()\n",
    "                raise ValueError('you need to specify a Youtube ID and an output filename')\n",
    "    '''\n",
    "    youtube_id=input('ID of Youtube video for which to download the comments ')\n",
    "    output=input('Output filename (output format is line delimited JSON) ')\n",
    "    limit =input ('Limit the number of comments ')\n",
    "    limit=int(limit)\n",
    "    print('Downloading Youtube comments for video:', youtube_id)\n",
    "    count = 0\n",
    "    with io.open(output, 'w', encoding='utf8') as fp:\n",
    "        for comment in download_comments(youtube_id):\n",
    "            print(json.dumps(comment, ensure_ascii=False), file=fp)\n",
    "            count += 1\n",
    "            sys.stdout.write('Downloaded %d comment(s)\\r' % count)\n",
    "            sys.stdout.flush()\n",
    "            if limit and count >= limit:\n",
    "                break\n",
    "    print('\\nDone!')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
